{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><center> <b>Sandpyper: sandy beaches SfM-UAV analysis tools</b></center></font>\n",
    "<font size=\"4\"><center> <b> Example 1 - Profiles extraction </b></center> <br>\n",
    "\n",
    "    \n",
    "<center><img src=\"images/banner.png\" width=\"80%\"  /></center>\n",
    "\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Profiles creation and data extraction from DSM and orthophotos</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Nicolas Pucino; PhD Student @ Deakin University, Australia </b> <br>\n",
    "\n",
    "<font size=\"3\">The first steps in a typical workflow is to create cross-shore transects in all the locations and extract elevation and RGB information along those transects. Sandpiper allows the data extraction from hundreds of rasters at once, in an organised way. <br>\n",
    "\n",
    "<b>This notebook covers the following concepts:</b>\n",
    "\n",
    "- Naming conventions and global parameters.\n",
    "- Setting up the folders.\n",
    "- Setting up the folders.\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all it is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pysal\\explore\\segregation\\network\\network.py:15: UserWarning: You need pandana and urbanaccess to work with segregation's network module\n",
      "You can install them with  `pip install urbanaccess pandana` or `conda install -c udst pandana urbanaccess`\n",
      "  warn(\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pysal\\model\\spvcm\\abstracts.py:10: UserWarning: The `dill` module is required to use the sqlite backend fully.\n",
      "  from .sqlite import head_to_sql, start_sql\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sandpyper.profile import ProfileSet\n",
    "from sandpyper.hotspot import ProfileDynamics\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirNameDSM=r'C:\\my_packages\\sandpyper\\tests\\test_data\\dsm_1m'\n",
    "dirNameOrtho=r'C:\\my_packages\\sandpyper\\tests\\test_data\\orthos_1m'\n",
    "dirNameTrans=r'C:\\my_packages\\sandpyper\\tests\\test_data\\transects'\n",
    "transects_spacing=20\n",
    "\n",
    "loc_codes=[\"mar\",\"leo\"]\n",
    "loc_search_dict = {   'leo': ['St','Leonards','leonards','leo'],\n",
    "                      'mar': ['Marengo','marengo','mar'] }\n",
    "crs_dict_string= {\n",
    "                 'mar': {'init': 'epsg:32754'},\n",
    "                 'leo':{'init': 'epsg:32755'}\n",
    "                 }\n",
    "lod_mode=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\lod_transects\"\n",
    "\n",
    "D=pickle.load(open(r\"C:\\my_packages\\sandpyper\\tests\\test_data\\test.p\", \"rb\"))\n",
    "\n",
    "loc_subset=[\"mar\"] # the function is optimised for single-location plots, but you can also pass a list of location codes\n",
    "colors_dict={\"mar\":'r',        # if you use multiple locations, then dictionary key is the location code and value the color\n",
    "            \"leo\":'b'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_dict={'leo_20180606':[0,9,10],\n",
    "'leo_20180713':[0,3,4,7],\n",
    "'leo_20180920':[0,2,6,7],\n",
    "'leo_20190211':[0,2,5],\n",
    "'leo_20190328':[2,4,5],\n",
    "'leo_20190731':[0,2,8,6],\n",
    "'mar_20180601':[1,6],\n",
    "'mar_20180621':[4,6],\n",
    "'mar_20180727':[0,5,9,10],\n",
    "'mar_20180925':[0],\n",
    "'mar_20181113':[1],\n",
    "'mar_20181211':[4],\n",
    "'mar_20190205':[],\n",
    "'mar_20190313':[],\n",
    "'mar_20190516':[4,7]}\n",
    "\n",
    "no_sand_dict={'leo_20180606':[5],\n",
    "'leo_20180713':[],\n",
    "'leo_20180920':[],\n",
    "'leo_20190211':[1],\n",
    "'leo_20190328':[],\n",
    "'leo_20190731':[1],\n",
    "'mar_20180601':[4,5],\n",
    "'mar_20180621':[3,5],\n",
    "'mar_20180727':[4,7],\n",
    "'mar_20180925':[1,6],\n",
    "'mar_20181113':[0],\n",
    "'mar_20181211':[0],\n",
    "'mar_20190205':[0,5],\n",
    "'mar_20190313':[4],\n",
    "'mar_20190516':[2,5]}\n",
    "\n",
    "veg_dict={'leo_20180606':[1,3,7,8],\n",
    "'leo_20180713':[1,5,9],\n",
    "'leo_20180920':[1,4,5],\n",
    "'leo_20190211':[4],\n",
    "'leo_20190328':[0,1,6],\n",
    "'leo_20190731':[3,7],\n",
    "'mar_20180601':[0,7],\n",
    "'mar_20180621':[1,7],\n",
    "'mar_20180727':[1,3],\n",
    "'mar_20180925':[4],\n",
    "'mar_20181113':[3],\n",
    "'mar_20181211':[2],\n",
    "'mar_20190205':[3],\n",
    "'mar_20190313':[1,5],\n",
    "'mar_20190516':[0]}\n",
    "\n",
    "sand_dict={'leo_20180606':[2,4,6],\n",
    "'leo_20180713':[2,6,8],\n",
    "'leo_20180920':[3],\n",
    "'leo_20190211':[3],\n",
    "'leo_20190328':[3],\n",
    "'leo_20190731':[4,5],\n",
    "'mar_20180601':[2,3],\n",
    "'mar_20180621':[0,2],\n",
    "'mar_20180727':[2,6,8],\n",
    "'mar_20180925':[2,3,5],\n",
    "'mar_20181113':[2,4],\n",
    "'mar_20181211':[3,1],\n",
    "'mar_20190205':[1,2,4],\n",
    "'mar_20190313':[0,2,3],\n",
    "'mar_20190516':[1,3,6]}\n",
    "\n",
    "\n",
    "l_dicts={'no_sand': no_sand_dict,\n",
    "         'sand': sand_dict,\n",
    "        'water': water_dict,\n",
    "        'veg':veg_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_corrections_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\label_corrections.gpkg\"\n",
    "watermasks_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\watermasks.gpkg\"\n",
    "shoremasks_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\shoremasks.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dicts_duplicated_values(l_dicts):\n",
    "\n",
    "    dict_check = {}\n",
    "    dict_dups = {}\n",
    "    all_dicts=[dicto for dicto in l_dicts.values()]\n",
    "\n",
    "    for dict_in in all_dicts:\n",
    "        for key in set().union(*all_dicts):\n",
    "            if key in dict_in:\n",
    "                dict_check.setdefault(key, []).extend(dict_in[key])\n",
    "\n",
    "    for survey, labels in dict_check.items():\n",
    "        duplicated=[x for x in labels if labels.count(x) > 1]\n",
    "        if len(duplicated)>=1:\n",
    "            dict_dups.update({survey:set(set(duplicated))})\n",
    "\n",
    "    if len(dict_dups)>0:\n",
    "        raise ValueError(f\"Duplicated label_k found in the following dictionaries.\\n\\n{dict_dups}\\n\\nPlease revise and assigned those labels_k to only one class dictionary.\")\n",
    "\n",
    "\n",
    "def classify_labelk(labelled_dataset,l_dicts, cluster_field='label_k', fill_class='sand'):\n",
    "\n",
    "    check_dicts_duplicated_values(l_dicts)\n",
    "    \n",
    "    labelled_dataset[\"pt_class\"]=np.nan\n",
    "    print(type(labelled_dataset))\n",
    "\n",
    "    all_keys = set().union(*(d.keys() for d in [i for i in l_dicts.values()]))\n",
    "    class_names=l_dicts.keys()\n",
    "\n",
    "    classed_df=pd.DataFrame()\n",
    "\n",
    "    for loc in labelled_dataset.location.unique():\n",
    "        data_in_loc=labelled_dataset.query(f\"location=='{loc}'\")[[\"location\",\"raw_date\",cluster_field,\"pt_class\",'point_id']]\n",
    "\n",
    "        for raw_date in data_in_loc.raw_date.unique():\n",
    "            loc_date_tag=f\"{loc}_{raw_date}\"\n",
    "            data_in=data_in_loc.query(f\"raw_date=={raw_date}\")\n",
    "\n",
    "            if loc_date_tag in all_keys:\n",
    "\n",
    "                for class_in in class_names:\n",
    "\n",
    "                    if loc_date_tag in l_dicts[class_in].keys():\n",
    "                        loc_date_class_values=l_dicts[class_in][loc_date_tag]\n",
    "\n",
    "                        if len(loc_date_class_values)>=1:\n",
    "                            tmp_dict={label_k:class_in for label_k in loc_date_class_values}\n",
    "                            data_in['pt_class'].update(data_in[cluster_field].map(tmp_dict))\n",
    "\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                print(f\"{loc_date_tag} not in the class dictionaries. All their labels assigned to fill_class {fill_class}.\")\n",
    "                data_in[\"pt_class\"].fillna(fill_class, inplace=True)\n",
    "\n",
    "            classed_df=pd.concat([classed_df,data_in], ignore_index=True)\n",
    "\n",
    "    merged=labelled_dataset.iloc[:,:-1].merge(right=classed_df[['point_id','pt_class']], on='point_id', how='left')\n",
    "    \n",
    "    merged[\"pt_class\"].fillna(fill_class, inplace=True)\n",
    "    print(type(merged))\n",
    "    return merged\n",
    "\n",
    "def cleanit(to_clean, l_dicts, cluster_field='label_k', fill_class='sand',\n",
    "            watermasks_path=None, water_label='water',\n",
    "            shoremasks_path=None, label_corrections_path=None,\n",
    "            default_crs={'init': 'epsg:32754'}, crs_dict_string=None,\n",
    "           geometry_field='coordinates'):\n",
    "    \n",
    "    print(\"Reclassifying dataset with the provided dictionaries.\" )\n",
    "    to_clean_classified=classify_labelk(to_clean, l_dicts)\n",
    "        \n",
    "    if watermasks_path==None and shoremasks_path==None and label_corrections_path==None:\n",
    "        print(\"No cleaning polygones have been passed. Returning classified dataset.\")\n",
    "        return to_clean_classified\n",
    "    \n",
    "    processes=[]\n",
    "        \n",
    "    \n",
    "    if label_corrections_path != None and os.path.isfile(label_corrections_path):\n",
    "        label_corrections=gpd.read_file(label_corrections_path)\n",
    "        print(f\"Label corrections provided in CRS: {label_corrections.crs}\")\n",
    "        processes.append(\"polygon finetuning\")\n",
    "        to_update_finetune=pd.DataFrame()\n",
    "        \n",
    "                \n",
    "        for loc in label_corrections.location.unique():\n",
    "            print(f\"Fine tuning in {loc}.\")\n",
    "            \n",
    "            to_clean_subset_loc=to_clean_classified.query(f\" location == '{loc}'\")\n",
    "            \n",
    "            for raw_date in tqdm(label_corrections.query(f\"location=='{loc}'\").raw_date.unique()):\n",
    "                \n",
    "                subset_finetune_polys=label_corrections.query(f\"location=='{loc}' and raw_date== {int(raw_date)}\")\n",
    "                \n",
    "                for i,row in subset_finetune_polys.iterrows(): # loops through all the polygones\n",
    "\n",
    "                    target_k=int(row['target_label_k'])\n",
    "                    new_class=row['new_class']\n",
    "                                        \n",
    "                    if target_k != 999:\n",
    "                        data_in=to_clean_subset_loc.query(f\"raw_date == '{str(raw_date)}' and label_k== {target_k}\")\n",
    "                        \n",
    "                    elif target_k == 999:\n",
    "                        data_in=to_clean_subset_loc.query(f\"raw_date == '{str(raw_date)}'\")\n",
    "                        \n",
    "                    selection=data_in[data_in.coordinates.intersects(row.geometry)]\n",
    "                    \n",
    "                    if selection.shape[0]==0:\n",
    "                        selection=data_in[data_in.to_crs(crs_dict_string[loc]).coordinates.intersects(row.geometry)]\n",
    "                    else:\n",
    "                        pass\n",
    "                    selection[\"finetuned_label\"]=new_class\n",
    "\n",
    "                    print(f\"Fine-tuning label_k {target_k} to {new_class} in {loc}-{raw_date}, found {selection.shape[0]} pts.\")\n",
    "                    to_update_finetune=pd.concat([selection,to_update_finetune], ignore_index=True)\n",
    "        \n",
    "        classed_df_finetuned=to_clean_classified.merge(right=to_update_finetune.loc[:,['point_id','finetuned_label']], # Left Join \n",
    "                                     how='left', validate='one_to_one') \n",
    "        \n",
    "        classed_df_finetuned.finetuned_label.fillna(classed_df_finetuned.pt_class, inplace=True) # Fill NaN with previous sand labels\n",
    "\n",
    "        print(type(classed_df_finetuned))\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if shoremasks_path == None and watermasks_path == None:\n",
    "        print(f\"{processes} completed.\")\n",
    "        return classed_df_finetuned\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    if watermasks_path != None and os.path.isfile(watermasks_path):\n",
    "        # apply watermasks\n",
    "        watermask=gpd.read_file(watermasks_path)\n",
    "        print(f\"watermask  provided in CRS: {watermask.crs}\")\n",
    "\n",
    "        \n",
    "        print(\"Applying watermasks cleaning.\")\n",
    "        processes.append(\"watermasking\")\n",
    "        \n",
    "        if \"polygon finetuning\" in processes:\n",
    "            dataset_to_clean=classed_df_finetuned\n",
    "            starting_labels='finetuned_label'\n",
    "        else:\n",
    "            dataset_to_clean=to_clean_classified\n",
    "            starting_labels='pt_class'\n",
    "            \n",
    "        \n",
    "        to_update_watermasked=pd.DataFrame()\n",
    "\n",
    "        for loc in watermask.location.unique():\n",
    "            print(f\"Watermasking in {loc}.\")\n",
    "            \n",
    "            for raw_date in tqdm(watermask.query(f\"location=='{loc}'\").raw_date.unique()):\n",
    "\n",
    "                subset_data=dataset_to_clean.query(f\"location=='{loc}' and raw_date == '{str(raw_date)}'\")\n",
    "                subset_masks=watermask.query(f\"location=='{loc}' and raw_date == {int(raw_date)}\")\n",
    "\n",
    "                selection=subset_data[subset_data.geometry.intersects(subset_masks.geometry)]\n",
    "                if selection.shape[0]==0:\n",
    "                    selection=subset_data[subset_data.geometry.intersects(subset_masks.to_crs(crs_dict_string[loc]).geometry.any())]\n",
    "                else:\n",
    "                    pass       \n",
    "                \n",
    "                print(f\"Setting to {water_label} {selection.shape[0]} pts overlapping provided watermasks.\")\n",
    "                \n",
    "                selection[\"watermasked_label\"]=water_label\n",
    "\n",
    "                to_update_watermasked=pd.concat([selection,to_update_watermasked], ignore_index=True)\n",
    "\n",
    "        classed_df_watermasked=dataset_to_clean.merge(right=to_update_watermasked.loc[:,['point_id','watermasked_label']], # Left Join \n",
    "                                     how='left', validate='one_to_one') \n",
    "        classed_df_watermasked.watermasked_label.fillna(classed_df_watermasked.loc[:,starting_labels], inplace=True) # Fill NaN with previous sand labels\n",
    "        \n",
    "        if shoremasks_path == None:\n",
    "            print(f\"{processes} completed.\")\n",
    "            return classed_df_watermasked\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if shoremasks_path != None and os.path.isfile(shoremasks_path):\n",
    "        # apply shoremasks\n",
    "        shoremask=gpd.read_file(shoremasks_path)\n",
    "        print(f\"shoremask  provided in CRS: {shoremask.crs}\")\n",
    "        print(\"Applying shoremasks cleaning.\")\n",
    "        processes.append(\"shoremasking\")\n",
    "        \n",
    "        \n",
    "        if \"polygon finetuning\" in processes and \"watermasking\" not in processes:\n",
    "            dataset_to_clean=classed_df_finetuned\n",
    "            starting_labels='finetuned_label'\n",
    "        elif \"polygon finetuning\" not in processes and \"watermasking\" in processes:\n",
    "            dataset_to_clean=classed_df_watermasked\n",
    "            starting_labels='watermasked_label'\n",
    "        else:\n",
    "            dataset_to_clean=to_clean_classified\n",
    "            starting_labels='pt_class'\n",
    "        \n",
    "        inshore_cleaned=gpd.GeoDataFrame()\n",
    "        for loc in shoremask.location.unique():\n",
    "            print(f\"Shoremasking in {loc}.\")\n",
    "            \n",
    "            shore=shoremask.query(f\"location=='{loc}'\")\n",
    "            loc_selection=dataset_to_clean.query(f\"location=='{loc}'\")\n",
    "            in_shore=loc_selection[loc_selection.geometry.intersects(shore.geometry)]\n",
    "            if in_shore.shape[0]>=1:\n",
    "                pass\n",
    "            else:\n",
    "                in_shore=loc_selection[loc_selection.geometry.intersects(shore.to_crs(crs_dict_string[loc]).geometry.any())]\n",
    "            \n",
    "            print(f\"Removing {loc_selection.shape[0] - in_shore.shape[0]} pts falling outside provided shore polygones.\")\n",
    "            inshore_cleaned=pd.concat([in_shore,inshore_cleaned], ignore_index=True)\n",
    "\n",
    "    print(f\"{processes} completed.\")\n",
    "    return inshore_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=cleanit(to_clean=P.profiles,\n",
    "        l_dicts=l_dicts, crs_dict_string=P.crs_dict_string,\n",
    "        watermasks_path=watermasks_path, shoremasks_path=shoremasks_path,label_corrections_path=label_corrections_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classed_df=to_clean_classified=classify_labelk(P.profiles, l_dicts)\n",
    "label_corrections=gpd.read_file(label_corrections_path)\n",
    "\n",
    "loc='leo'\n",
    "raw_date=20190328\n",
    "target_k=1\n",
    "\n",
    "mask=label_corrections.query(f\"location=='{loc}'and raw_date == {int(raw_date)} and target_label_k== {target_k}\").iloc[0]\n",
    "data_in=classed_df.query(f\"location=='{loc}' and raw_date == '{str(raw_date)}' and label_k== {target_k}\")\n",
    "\n",
    "selection=data_in[data_in.coordinates.intersects(mask.geometry)]\n",
    "print(selection.shape[0])                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.cleanit(to_clean=P.profiles,l_dicts=l_dicts, crs_dict_string=P.crs_dict_string,\n",
    "        watermasks_path=watermasks_path, shoremasks_path=shoremasks_path,label_corrections_path=label_corrections_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in subset_finetune_polys.iterrows(): # loops through all the polygones\n",
    "\n",
    "    target_k=int(row['target_label_k'])\n",
    "    new_class=row['new_class']\n",
    "\n",
    "    if target_k != 999:\n",
    "\n",
    "        data_in=to_clean_subset_loc.query(f\"raw_date == {raw_date} and label_k=={target_k}\")\n",
    "        selection=data_in[data_in.coordinates.intersects(row.geometry.iloc[0])]\n",
    "        selection[\"finetuned_label\"]=new_class\n",
    "\n",
    "    elif target_k == 999:\n",
    "\n",
    "        data_in=to_clean_subset_loc.query(f\"raw_date == {raw_date}\")\n",
    "        selection=data_in[data_in.coordinates.intersects(row['geometry'])]\n",
    "        selection[\"finetuned_label\"]=new_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.ProfileSet.profiles.to_csv(r\"C:\\my_packages\\sandpyper\\tests\\test_data\\test_to_classify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.BCD_compute_transects(thresh=7, min_points=20,reliable_action='keep', dirNameTrans=D.ProfileSet.dirNameTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.transects_rbcd.query(\"location=='leo'\").plot(column=\"residual\", cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity Analysis r-bcd transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sandpyper.dynamics import get_rbcd_transect\n",
    "import seaborn as sb\n",
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_thresh=range(0,data_in.dt.unique().shape[0]+1)\n",
    "range_min_pts=range(0,50,10)\n",
    "combs = list(itertools.product(range_min_pts,range_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss_tr_big=pd.DataFrame()\n",
    "\n",
    "for i in tqdm(combs):\n",
    "    print(f\"Working on threshold {i[1]} and min points {i[0]}.\")\n",
    "    \n",
    "    ss_transects_idx = get_rbcd_transect(df_labelled=data_in,\n",
    "              thresh=i[1], min_points=i[0], reliable_action='drop',\n",
    "              dirNameTrans=D.ProfileSet.dirNameTrans,\n",
    "              labels_order=D.tags_order,\n",
    "              loc_codes=D.ProfileSet.loc_codes,\n",
    "              crs_dict_string=D.ProfileSet.crs_dict_string)\n",
    "\n",
    "    ss_transects_idx['thresh']=i[1]\n",
    "    ss_transects_idx['min_pts']=i[0]\n",
    "\n",
    "    ss_tr_big=pd.concat([ss_tr_big,ss_transects_idx], ignore_index=True)\n",
    "    \n",
    "ss_tr_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(10,10))\n",
    "\n",
    "palette=sb.color_palette( n_colors=ss_tr_big.tr_id.unique().shape[0])\n",
    "sb.lineplot(data=ss_tr_big, x='thresh',y='residual', hue='tr_id',\n",
    "            palette=palette, legend=False, **dict(alpha=0.1),\n",
    "            ax=ax\n",
    ")\n",
    "ax.set_ylabel(\"r_bcd\")\n",
    "ax.axhline(y=0, lw=2, c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_res_ar=ss_tr_big_loc.groupby([\"tr_id\",\"min_pts\"])['residual'].apply(np.array).reset_index()\n",
    "tot_trs=ss_tr_big_loc.groupby([\"thresh\",\"min_pts\"])['geometry'].count().reset_index()\n",
    "tot_trs['trs_10']=tot_trs.geometry / 10\n",
    "zero_crossings=pd.DataFrame([pd.Series({'tr_id':trs_res_ar.loc[i,'tr_id'],\n",
    "                                        'sign_change_thresh':np.where(np.diff(np.sign(trs_res_ar.iloc[i,-1])))[0][-1]+1,\n",
    "                                       'min_pts':trs_res_ar.loc[i,'min_pts']}) for i in range(trs_res_ar.shape[0]) if np.where(np.diff(np.sign(trs_res_ar.iloc[i,-1])))[0].shape[0] !=0])\n",
    "tot_jumps=zero_crossings.groupby([\"sign_change_thresh\",\"min_pts\"]).count().reset_index() # how many jumps per thresh and minpts\n",
    "\n",
    "joined=pd.merge(tot_trs,tot_jumps, left_on=['thresh','min_pts'], right_on=['sign_change_thresh','min_pts'], how='left')\n",
    "joined.rename({'geometry':'tot_trs',\n",
    "              'tr_id':'tot_jumps'}, axis=1, inplace=True)\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "# Then, \"ALWAYS use sans-serif fonts\"\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "sb.set_context(\"paper\", font_scale=2.8)\n",
    "\n",
    "\n",
    "x_ticks=[0,2,4,6,8]\n",
    "\n",
    "q_up_val=0.95\n",
    "q_low_val=0.85\n",
    "\n",
    "list_minpts=ss_tr_big.min_pts.unique()\n",
    "\n",
    "for minpts in list_minpts:\n",
    "\n",
    "    f,ax=plt.subplots(figsize=(7,4))\n",
    "    ax2=ax.twinx()\n",
    "    \n",
    "    datain=joined.query(f\"min_pts=={minpts}\")  \n",
    "\n",
    "\n",
    "    sb.lineplot(x=\"thresh\", y=\"tot_jumps\",ci=None,\n",
    "                    data=datain,color='b',\n",
    "                   alpha=.4,linewidth=3,\n",
    "                ax=ax2, label=\"sign changes\")\n",
    "\n",
    "    sb.lineplot(data=datain,x='thresh',y='trs_10',\n",
    "                alpha=.4,color='r',linewidth=3,\n",
    "                ax=ax,label=\"transects * 10\")\n",
    "    \n",
    "    \n",
    "    kde_x, kde_y = ax.lines[0].get_data()\n",
    "    kde_x2, kde_y2 = ax2.lines[0].get_data()\n",
    "    ax.fill_between(kde_x, kde_y,interpolate=True, color='r',alpha=0.5)\n",
    "    ax2.fill_between(kde_x2, kde_y2,interpolate=True,color='b',alpha=0.5)\n",
    "    \n",
    "    ax.axhline((datain.tot_trs.fillna(0).max()*q_up_val)/10,c='k',ls='-',label='95%')\n",
    "    ax.axhline((datain.tot_trs.fillna(0).max()*q_low_val)/10,c='k',lw=2.5,ls='--',label='85%')\n",
    "    \n",
    "    ax.set_ylabel('n. transects x 10', c='r')\n",
    "    ax.set_xlabel('t')\n",
    "    ax2.set_ylabel('sign changes', c='b')\n",
    "    ax2.set_ylim(0,3)\n",
    "    ax.set_ylim(0,3)\n",
    "    ax.set_xlim(0,8)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    ax.get_legend().remove()\n",
    "    ax2.get_legend().remove()\n",
    "    \n",
    "    \n",
    "    plt.xticks(x_ticks)\n",
    "    savetxt=f\"E:\\\\path\\\\to\\\\save\\\\revision_0\\\\location_sensit_minpts_{minpts}.png\"\n",
    "    \n",
    "    ax.set_title(f\"pt: {minpts}\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "#   f.savefig(savetxt, dpi=600); #uncomment to save all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProfileSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsm from leo = 6\n",
      "\n",
      "ortho from leo = 6\n",
      "\n",
      "dsm from mar = 9\n",
      "\n",
      "ortho from mar = 9\n",
      "\n",
      "\n",
      "NUMBER OF DATASETS TO PROCESS: 30\n"
     ]
    }
   ],
   "source": [
    "P=ProfileSet(dirNameDSM=dirNameDSM,\n",
    "            dirNameOrtho=dirNameOrtho,\n",
    "            dirNameTrans=dirNameTrans,\n",
    "            transects_spacing=transects_spacing,\n",
    "            loc_codes=loc_codes,\n",
    "            loc_search_dict=loc_search_dict,\n",
    "            crs_dict_string=crs_dict_string,\n",
    "            check=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting elevation from DSMs . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2474f3b9ae4c4dbfcf99ede6a3a30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ac93ff07e946cabe618bd150dda4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d68b9911fd4a63914d4135e5519c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12304fda3b994f0a869f3a3739219b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938aebf2bc0b49419dd6b755a29615b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06af970dca7f4acfb5fb6237504f1bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fae002e6204cd18d3c73b613a0b094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8b494757534835bd7a14dfd8719d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e863684f175a410ebe3279d66878400e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94896d9980b64516b96a77d6c1597fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd89112c46b847d9b6baae4bfc0af2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe81d57c7fe42de9d36b43cb18899f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4585e836503c42c3b026b702b768d1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d8700a7dab44ee8fc02fae2d1a74ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918f0024ce664a16a8d599472f81f83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43f58c7ebff46cd945e7048f978e233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction succesfull\n",
      "Number of points extracted:32805\n",
      "Time for processing=40.33010149002075 seconds\n",
      "First 10 rows are printed below\n",
      "Number of points outside the raster extents: 9066\n",
      "The extraction assigns NaN.\n",
      "Number of points in NoData areas within the raster extents: 250\n",
      "The extraction assigns NaN.\n",
      "Extracting rgb values from orthos . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e0f235ed0d4cdc8a663df887e81edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd053829543c41b6a7261e901e5bead7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d35f652d0144c5b9512ef33ab0ae5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a90d4e24141b2a08e4917b19e2524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe808b79a0ef4ecb95b8771724d0769d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97dc2bff69443ed90303b612dbd165c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c511d69833f941f38368c5458a4395f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5446340663c423ab8b5e9f9e04ba55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f6d89b6c3949a783ede91d0ac40ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861519177c464a7fa8dc69f40217463f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce8544c55b44e8192dfec8ffdd7addd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb435515acf4e93bd2d86e51e2606a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d500059953f4447ea0d9119bd596dd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041c87a0e46943ca9c1d995c91c7fd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f832571c84c3478da249e9acc3c95bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dbb9d611f74e1091a670ef25372396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction succesfull\n",
      "Number of points extracted:32805\n",
      "Time for processing=41.140849351882935 seconds\n",
      "First 10 rows are printed below\n",
      "Number of points outside the raster extents: 27198\n",
      "The extraction assigns NaN.\n",
      "Number of points in NoData areas within the raster extents: 0\n",
      "The extraction assigns NaN.\n",
      "Extracting LoD values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9778270ccaaf4396a482f665b1636f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191cd8637cda49ebbd9d19adce04e047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e30b618563e4eaaa96e685a492298d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871cfb0d3ad44e328ad1207a86eee29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b396a77a11634387929155d9334df6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f461095ca866447fbae76d44b66600fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b995114ef614260ac423f55d3167b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59839e3f089a4ed39a5d0025fc906776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae76f7003314f11b8afc67fe1326bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16452c52e2bb424b945d1d56070658e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e954b6bff04cef8cf54ba13102b909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d255371aca247758dd7b0f9b2f473c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fd0a6b4f14490e8b843719e498dfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8645a3be984b2db8ec3044678d0f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dd0232b00a4a1c83773cffbf75ec6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6d907fac26442595b5e5a2dcc5fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction succesfull\n",
      "Number of points extracted:1395\n",
      "Time for processing=4.717918872833252 seconds\n",
      "First 10 rows are printed below\n",
      "Number of points outside the raster extents: 27\n",
      "The extraction assigns NaN.\n",
      "Number of points in NoData areas within the raster extents: 0\n",
      "The extraction assigns NaN.\n"
     ]
    }
   ],
   "source": [
    "P.extract_profiles(mode='all',sampling_step=1,add_xy=True,lod_mode=lod_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(P.profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sandpyper.labels import get_sil_location, get_opt_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cd992a9d234433b96eb16a1bdada0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82f3e1e6c7a47d1af81921f125b77bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on : mar, 20190516.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5f7aebfef74a9e8c92b4a27032afd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.6219865168763407\n",
      "For n_clusters = 3 The average silhouette_score is : 0.535782834177223\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5360693626824162\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4560535847617118\n",
      "For n_clusters = 6 The average silhouette_score is : 0.45529082978244856\n",
      "For n_clusters = 7 The average silhouette_score is : 0.44623104595368007\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4276467073078296\n",
      "For n_clusters = 9 The average silhouette_score is : 0.39984472497160034\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3944833658664287\n",
      "For n_clusters = 11 The average silhouette_score is : 0.39290037915600995\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3626866522843635\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3537214969510808\n",
      "For n_clusters = 14 The average silhouette_score is : 0.360049558138258\n",
      "Working on : mar, 20190313.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d964ffa0657440b3b894caed8e6820cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.557958595647791\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5140648301846097\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5018436513556769\n",
      "For n_clusters = 5 The average silhouette_score is : 0.433979206893076\n",
      "For n_clusters = 6 The average silhouette_score is : 0.417124057365699\n",
      "For n_clusters = 7 The average silhouette_score is : 0.41877526043796687\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3813644990945346\n",
      "For n_clusters = 9 The average silhouette_score is : 0.38298598316290156\n",
      "For n_clusters = 10 The average silhouette_score is : 0.38780357139523025\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3705944933198418\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3651637741592011\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3626901435079943\n",
      "For n_clusters = 14 The average silhouette_score is : 0.364312347054231\n",
      "Working on : mar, 20190205.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25ee23c8dec4e4aae7d49be1d94d593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5864811907668233\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5287826504696901\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5135421029464969\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4307716357147362\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4198951039452866\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4216561839748987\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4048963177852256\n",
      "For n_clusters = 9 The average silhouette_score is : 0.40309220394346107\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3863324302013023\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3797930282754271\n",
      "For n_clusters = 12 The average silhouette_score is : 0.38096229910474133\n",
      "For n_clusters = 13 The average silhouette_score is : 0.38270148296414735\n",
      "For n_clusters = 14 The average silhouette_score is : 0.38101196831610196\n",
      "Working on : mar, 20181211.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cdb89d49174654a9565b3daab70f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5408421089322027\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5230591336669079\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5212604455141028\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4229400387683722\n",
      "For n_clusters = 6 The average silhouette_score is : 0.45245862927127983\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4483238394769186\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4196417680949735\n",
      "For n_clusters = 9 The average silhouette_score is : 0.40611511715414134\n",
      "For n_clusters = 10 The average silhouette_score is : 0.38659542553842996\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3696055524901218\n",
      "For n_clusters = 12 The average silhouette_score is : 0.37009962399500085\n",
      "For n_clusters = 13 The average silhouette_score is : 0.35527656663572244\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3465435289160837\n",
      "Working on : mar, 20181113.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456c94e4991d4a5ba662dcb72652f10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5653353599190023\n",
      "For n_clusters = 3 The average silhouette_score is : 0.48082172651613736\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4739355249881875\n",
      "For n_clusters = 5 The average silhouette_score is : 0.44998542160594424\n",
      "For n_clusters = 6 The average silhouette_score is : 0.46793686792032685\n",
      "For n_clusters = 7 The average silhouette_score is : 0.45141377362406754\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4282875609756635\n",
      "For n_clusters = 9 The average silhouette_score is : 0.41407851845524357\n",
      "For n_clusters = 10 The average silhouette_score is : 0.40718423656045105\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3903647922431344\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3839833647433829\n",
      "For n_clusters = 13 The average silhouette_score is : 0.38065272471925277\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3832072967705472\n",
      "Working on : mar, 20180925.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40571c300124826b0e8d18b89c00531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5781993163219185\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5170856406873439\n",
      "For n_clusters = 4 The average silhouette_score is : 0.48466929384434043\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4373504056027659\n",
      "For n_clusters = 6 The average silhouette_score is : 0.39375906953445383\n",
      "For n_clusters = 7 The average silhouette_score is : 0.38864190848914665\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4035256487664215\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3798356038299367\n",
      "For n_clusters = 10 The average silhouette_score is : 0.37962054426443537\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3644375001522226\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3558265298038209\n",
      "For n_clusters = 13 The average silhouette_score is : 0.34528697717595713\n",
      "For n_clusters = 14 The average silhouette_score is : 0.35004508855406896\n",
      "Working on : mar, 20180727.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9571ceb2a2ff4c509ea0edc87c5af2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5803251747670938\n",
      "For n_clusters = 3 The average silhouette_score is : 0.48850610227959923\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4772654299979584\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4135001777584117\n",
      "For n_clusters = 6 The average silhouette_score is : 0.38283314263428714\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3755827513627956\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3486272625814806\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3367906257895182\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3273888373123684\n",
      "For n_clusters = 11 The average silhouette_score is : 0.30071888963336296\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3219840164575009\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3222155159146202\n",
      "For n_clusters = 14 The average silhouette_score is : 0.307958370621084\n",
      "Working on : mar, 20180621.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250db26c628541909ad21d994d52953c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5439589764752933\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4387708619085413\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4501935908699898\n",
      "For n_clusters = 5 The average silhouette_score is : 0.3963414382040067\n",
      "For n_clusters = 6 The average silhouette_score is : 0.41807731086369254\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3871968978951222\n",
      "For n_clusters = 8 The average silhouette_score is : 0.37393061831106983\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3443142601476958\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3585650473719073\n",
      "For n_clusters = 11 The average silhouette_score is : 0.35570748604269775\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3575633171508779\n",
      "For n_clusters = 13 The average silhouette_score is : 0.37087632012718563\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3795271430686032\n",
      "Working on : mar, 20180601.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b3a9e8adad4f69a91dad80aea684c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.48270415311106846\n",
      "For n_clusters = 3 The average silhouette_score is : 0.3772084152830261\n",
      "For n_clusters = 4 The average silhouette_score is : 0.38234628609235827\n",
      "For n_clusters = 5 The average silhouette_score is : 0.38128225187445997\n",
      "For n_clusters = 6 The average silhouette_score is : 0.36428432858349613\n",
      "For n_clusters = 7 The average silhouette_score is : 0.36240034713437685\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3701424025696913\n",
      "For n_clusters = 9 The average silhouette_score is : 0.37175207788683484\n",
      "For n_clusters = 10 The average silhouette_score is : 0.37676977350569846\n",
      "For n_clusters = 11 The average silhouette_score is : 0.37582649170780724\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3619596723553155\n",
      "For n_clusters = 13 The average silhouette_score is : 0.360705274650356\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3549151019500089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed105889689d49bb8b83c7ed15ccc02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on : leo, 20190731.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c10461d05049fc96dafad745fc0b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.3899198233106219\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5071438060156596\n",
      "For n_clusters = 4 The average silhouette_score is : 0.47005119135652856\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4481907289981238\n",
      "For n_clusters = 6 The average silhouette_score is : 0.42502882450684076\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4011433092740131\n",
      "For n_clusters = 8 The average silhouette_score is : 0.38998808479733066\n",
      "For n_clusters = 9 The average silhouette_score is : 0.38559916622535073\n",
      "For n_clusters = 10 The average silhouette_score is : 0.38736594985557654\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3788805356672864\n",
      "For n_clusters = 12 The average silhouette_score is : 0.37132878563783606\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3728000521740459\n",
      "For n_clusters = 14 The average silhouette_score is : 0.37291633707910765\n",
      "Working on : leo, 20190328.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d18eab8d25e4faabf74cff3a7ec3fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.3988524141238273\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4304685615621422\n",
      "For n_clusters = 4 The average silhouette_score is : 0.431227035737659\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4509750902886234\n",
      "For n_clusters = 6 The average silhouette_score is : 0.42012497505273527\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4094032569946379\n",
      "For n_clusters = 8 The average silhouette_score is : 0.42729379253757904\n",
      "For n_clusters = 9 The average silhouette_score is : 0.41690585873078206\n",
      "For n_clusters = 10 The average silhouette_score is : 0.4226788217215935\n",
      "For n_clusters = 11 The average silhouette_score is : 0.41351261817558693\n",
      "For n_clusters = 12 The average silhouette_score is : 0.4087415403998031\n",
      "For n_clusters = 13 The average silhouette_score is : 0.38543846003780563\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3783301865582882\n",
      "Working on : leo, 20190211.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ad4f2730c54830a4ef05183c6a87eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.3811803323084047\n",
      "For n_clusters = 3 The average silhouette_score is : 0.48727929000883047\n",
      "For n_clusters = 4 The average silhouette_score is : 0.44313687819005354\n",
      "For n_clusters = 5 The average silhouette_score is : 0.45097582364485633\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4320727369612193\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4166514336483687\n",
      "For n_clusters = 8 The average silhouette_score is : 0.39445247084076124\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3718047003108205\n",
      "For n_clusters = 10 The average silhouette_score is : 0.36905766574894283\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3723670925736636\n",
      "For n_clusters = 12 The average silhouette_score is : 0.35518841237259613\n",
      "For n_clusters = 13 The average silhouette_score is : 0.35415290301652735\n",
      "For n_clusters = 14 The average silhouette_score is : 0.33383141602938693\n",
      "Working on : leo, 20180920.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dbbcc4006c4430ae2a0cfeaa4c22cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.4039166622963731\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4367493135688848\n",
      "For n_clusters = 4 The average silhouette_score is : 0.42434419318841404\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4443994359362926\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4175864662989779\n",
      "For n_clusters = 7 The average silhouette_score is : 0.38860870508958795\n",
      "For n_clusters = 8 The average silhouette_score is : 0.38880003508342514\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3830287983992327\n",
      "For n_clusters = 10 The average silhouette_score is : 0.37353163965128733\n",
      "For n_clusters = 11 The average silhouette_score is : 0.36620965721819637\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3536600836899299\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3585083805642395\n",
      "For n_clusters = 14 The average silhouette_score is : 0.35672016047028215\n",
      "Working on : leo, 20180713.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26b4d474f9f43bd897a78972240cda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.49629965872244686\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5092406492417487\n",
      "For n_clusters = 4 The average silhouette_score is : 0.46159478658042724\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4488595142176017\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4183623304561938\n",
      "For n_clusters = 7 The average silhouette_score is : 0.39004221840210485\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3842278112748862\n",
      "For n_clusters = 9 The average silhouette_score is : 0.36304035595403583\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3463760386521644\n",
      "For n_clusters = 11 The average silhouette_score is : 0.34841430296451464\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3460546307634773\n",
      "For n_clusters = 13 The average silhouette_score is : 0.34457917043266856\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3318667826222712\n",
      "Working on : leo, 20180606.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371187b8d4f74114a13d7924cff1ef2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.4012079287817844\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4563078554750914\n",
      "For n_clusters = 4 The average silhouette_score is : 0.40640166442880776\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4001757072050638\n",
      "For n_clusters = 6 The average silhouette_score is : 0.3890044660503746\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3716889344520391\n",
      "For n_clusters = 8 The average silhouette_score is : 0.36600629265911533\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3503569988098764\n",
      "For n_clusters = 10 The average silhouette_score is : 0.34651080656561367\n",
      "For n_clusters = 11 The average silhouette_score is : 0.34322073624826754\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3439561998875081\n",
      "For n_clusters = 13 The average silhouette_score is : 0.347961415981389\n",
      "For n_clusters = 14 The average silhouette_score is : 0.33782737875946023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>k</th>\n",
       "      <th>silhouette_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.621987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>3</td>\n",
       "      <td>0.535783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>4</td>\n",
       "      <td>0.536069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>5</td>\n",
       "      <td>0.456054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.455291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>leo</td>\n",
       "      <td>20180606</td>\n",
       "      <td>10</td>\n",
       "      <td>0.346511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>leo</td>\n",
       "      <td>20180606</td>\n",
       "      <td>11</td>\n",
       "      <td>0.343221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>leo</td>\n",
       "      <td>20180606</td>\n",
       "      <td>12</td>\n",
       "      <td>0.343956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>leo</td>\n",
       "      <td>20180606</td>\n",
       "      <td>13</td>\n",
       "      <td>0.347961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>leo</td>\n",
       "      <td>20180606</td>\n",
       "      <td>14</td>\n",
       "      <td>0.337827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    location  raw_date   k  silhouette_mean\n",
       "0        mar  20190516   2         0.621987\n",
       "1        mar  20190516   3         0.535783\n",
       "2        mar  20190516   4         0.536069\n",
       "3        mar  20190516   5         0.456054\n",
       "4        mar  20190516   6         0.455291\n",
       "..       ...       ...  ..              ...\n",
       "190      leo  20180606  10         0.346511\n",
       "191      leo  20180606  11         0.343221\n",
       "192      leo  20180606  12         0.343956\n",
       "193      leo  20180606  13         0.347961\n",
       "194      leo  20180606  14         0.337827\n",
       "\n",
       "[195 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run interatively KMeans + SA\n",
    "\n",
    "feature_set=[\"band1\",\"band2\",\"band3\",\"distance\"]\n",
    "sil_df=get_sil_location(P.profiles,\n",
    "                        ks=(2,15), \n",
    "                        feature_set=feature_set,\n",
    "                       random_state=10)\n",
    "sil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leo_20180606': 11,\n",
       " 'leo_20180713': 10,\n",
       " 'leo_20180920': 4,\n",
       " 'leo_20190211': 4,\n",
       " 'leo_20190328': 7,\n",
       " 'leo_20190731': 9,\n",
       " 'mar_20180601': 3,\n",
       " 'mar_20180621': 3,\n",
       " 'mar_20180727': 11,\n",
       " 'mar_20180925': 7,\n",
       " 'mar_20181113': 5,\n",
       " 'mar_20181211': 5,\n",
       " 'mar_20190205': 6,\n",
       " 'mar_20190313': 6,\n",
       " 'mar_20190516': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_k=get_opt_k(sil_df, sigma=0 )\n",
    "opt_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731646.904 5705523.469)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61121091m2580400ar00</td>\n",
       "      <td>731646.903760</td>\n",
       "      <td>5.705523e+06</td>\n",
       "      <td>114.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731646.078 5705524.033)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61123091m2580600ar10</td>\n",
       "      <td>731646.078301</td>\n",
       "      <td>5.705524e+06</td>\n",
       "      <td>117.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731645.253 5705524.598)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61129091m2530100ar20</td>\n",
       "      <td>731645.252842</td>\n",
       "      <td>5.705525e+06</td>\n",
       "      <td>122.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731644.427 5705525.162)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61124091m2570800ar30</td>\n",
       "      <td>731644.427383</td>\n",
       "      <td>5.705525e+06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731643.602 5705525.727)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61120091m2520400ar40</td>\n",
       "      <td>731643.601924</td>\n",
       "      <td>5.705526e+06</td>\n",
       "      <td>126.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance         z  tr_id  raw_date                     coordinates  \\\n",
       "0       0.0  0.007440     21  20190516  POINT (731646.904 5705523.469)   \n",
       "1       1.0  0.008439     21  20190516  POINT (731646.078 5705524.033)   \n",
       "2       2.0  0.010800     21  20190516  POINT (731645.253 5705524.598)   \n",
       "3       3.0  0.011350     21  20190516  POINT (731644.427 5705525.162)   \n",
       "4       4.0  0.028030     21  20190516  POINT (731643.602 5705525.727)   \n",
       "\n",
       "  location survey_date              point_id              x             y  \\\n",
       "0      mar  2019-05-16  61121091m2580400ar00  731646.903760  5.705523e+06   \n",
       "1      mar  2019-05-16  61123091m2580600ar10  731646.078301  5.705524e+06   \n",
       "2      mar  2019-05-16  61129091m2530100ar20  731645.252842  5.705525e+06   \n",
       "3      mar  2019-05-16  61124091m2570800ar30  731644.427383  5.705525e+06   \n",
       "4      mar  2019-05-16  61120091m2520400ar40  731643.601924  5.705526e+06   \n",
       "\n",
       "   band1  band2  band3  \n",
       "0  114.0  139.0  128.0  \n",
       "1  117.0  139.0  127.0  \n",
       "2  122.0  140.0  127.0  \n",
       "3  125.0  144.0  133.0  \n",
       "4  126.0  145.0  133.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c758ea981f0e48af84d5078dfe4af1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91eaf39e35454ad9921919875df11cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4709181e0c4af78d956ec85e95178e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>label_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.130296</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299873.218 5773731.860)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>67144080l2610600eo00</td>\n",
       "      <td>299873.217965</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>133.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.085163</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299874.212 5773731.971)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>67148080l2690700eo10</td>\n",
       "      <td>299874.211725</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>109.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.033864</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299875.205 5773732.083)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>67143080l2670800eo20</td>\n",
       "      <td>299875.205484</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.025817</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299876.199 5773732.194)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>67148080l2650800eo30</td>\n",
       "      <td>299876.199244</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.041824</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299877.193 5773732.306)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>67143080l2630900eo40</td>\n",
       "      <td>299877.193003</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>103.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance         z  tr_id  raw_date                     coordinates  \\\n",
       "0       0.0  1.130296     47  20180606  POINT (299873.218 5773731.860)   \n",
       "1       1.0  1.085163     47  20180606  POINT (299874.212 5773731.971)   \n",
       "2       2.0  1.033864     47  20180606  POINT (299875.205 5773732.083)   \n",
       "3       3.0  1.025817     47  20180606  POINT (299876.199 5773732.194)   \n",
       "4       4.0  1.041824     47  20180606  POINT (299877.193 5773732.306)   \n",
       "\n",
       "  location survey_date              point_id              x             y  \\\n",
       "0      leo  2018-06-06  67144080l2610600eo00  299873.217965  5.773732e+06   \n",
       "1      leo  2018-06-06  67148080l2690700eo10  299874.211725  5.773732e+06   \n",
       "2      leo  2018-06-06  67143080l2670800eo20  299875.205484  5.773732e+06   \n",
       "3      leo  2018-06-06  67148080l2650800eo30  299876.199244  5.773732e+06   \n",
       "4      leo  2018-06-06  67143080l2630900eo40  299877.193003  5.773732e+06   \n",
       "\n",
       "   band1  band2  band3  label_k  \n",
       "0  133.0  143.0  104.0        8  \n",
       "1  109.0  107.0  106.0        8  \n",
       "2   98.0   94.0  105.0        8  \n",
       "3   99.0   97.0  108.0        8  \n",
       "4  103.0  109.0  127.0        8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.kmeans_sa(opt_k,feature_set)\n",
    "\n",
    "P.profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sand_label, shore and water masks\n",
    "#P.sandonly(sand_dict, watermask, shoremask)  # watermasks and shoremasks need to be added to self.P for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_dict={'leo_20180606':[0,9,10],\n",
    "'leo_20180713':[0,3,4,7],\n",
    "'leo_20180920':[0,2,6,7],\n",
    "'leo_20190211':[0,2,5],\n",
    "'leo_20190328':[2,4,5],\n",
    "'leo_20190731':[0,2,8,6],\n",
    "'mar_20180601':[1,6],\n",
    "'mar_20180621':[4,6],\n",
    "'mar_20180727':[0,5,9,10],\n",
    "'mar_20180925':[0],\n",
    "'mar_20181113':[1],\n",
    "'mar_20181211':[4],\n",
    "'mar_20190205':[],\n",
    "'mar_20190313':[],\n",
    "'mar_20190516':[4,7]}\n",
    "\n",
    "no_sand_dict={'leo_20180606':[5],\n",
    "'leo_20180713':[],\n",
    "'leo_20180920':[],\n",
    "'leo_20190211':[1],\n",
    "'leo_20190328':[],\n",
    "'leo_20190731':[1],\n",
    "'mar_20180601':[4,5],\n",
    "'mar_20180621':[3,5],\n",
    "'mar_20180727':[4,7],\n",
    "'mar_20180925':[1,6],\n",
    "'mar_20181113':[0],\n",
    "'mar_20181211':[0],\n",
    "'mar_20190205':[0,5],\n",
    "'mar_20190313':[4],\n",
    "'mar_20190516':[2,5]}\n",
    "\n",
    "veg_dict={'leo_20180606':[1,3,7,8],\n",
    "'leo_20180713':[1,5,9],\n",
    "'leo_20180920':[1,4,5],\n",
    "'leo_20190211':[4],\n",
    "'leo_20190328':[0,1,6],\n",
    "'leo_20190731':[3,7],\n",
    "'mar_20180601':[0,7],\n",
    "'mar_20180621':[1,7],\n",
    "'mar_20180727':[1,3],\n",
    "'mar_20180925':[4],\n",
    "'mar_20181113':[3],\n",
    "'mar_20181211':[2],\n",
    "'mar_20190205':[3],\n",
    "'mar_20190313':[1,5],\n",
    "'mar_20190516':[0]}\n",
    "\n",
    "sand_dict={'leo_20180606':[2,4,6],\n",
    "'leo_20180713':[2,6,8],\n",
    "'leo_20180920':[3],\n",
    "'leo_20190211':[3],\n",
    "'leo_20190328':[3],\n",
    "'leo_20190731':[4,5],\n",
    "'mar_20180601':[2,3],\n",
    "'mar_20180621':[0,2],\n",
    "'mar_20180727':[2,6,8],\n",
    "'mar_20180925':[2,3,5],\n",
    "'mar_20181113':[2,4],\n",
    "'mar_20181211':[3,1],\n",
    "'mar_20190205':[1,2,4],\n",
    "'mar_20190313':[0,2,3],\n",
    "'mar_20190516':[1,3,6]}\n",
    "\n",
    "\n",
    "l_dicts={'no_sand': no_sand_dict,\n",
    "         'sand': sand_dict,\n",
    "        'water': water_dict,\n",
    "        'veg':veg_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_corrections_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\label_corrections.gpkg\"\n",
    "watermasks_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\watermasks.gpkg\"\n",
    "shoremasks_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\shoremasks.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassifying dataset with the provided dictionaries.\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Label corrections provided in CRS: epsg:32754\n",
      "Fine tuning in leo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f598adb6de046f0b80694d66dac9be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning label_k 3 to no_sand in leo-20180606, found 127 pts.\n",
      "Fine-tuning label_k 8 to no_sand in leo-20180606, found 73 pts.\n",
      "Fine-tuning label_k 5 to no_sand in leo-20180713, found 56 pts.\n",
      "Fine-tuning label_k 6 to no_sand in leo-20180713, found 7 pts.\n",
      "Fine-tuning label_k 1 to no_sand in leo-20180920, found 89 pts.\n",
      "Fine-tuning label_k 2 to sand in leo-20180920, found 9 pts.\n",
      "Fine-tuning label_k 2 to veg in leo-20180920, found 31 pts.\n",
      "Fine-tuning label_k 6 to sand in leo-20180920, found 17 pts.\n",
      "Fine-tuning label_k 2 to veg in leo-20190211, found 2 pts.\n",
      "Fine-tuning label_k 6 to veg in leo-20190211, found 29 pts.\n",
      "Fine-tuning label_k 6 to no_sand in leo-20190211, found 2 pts.\n",
      "Fine-tuning label_k 6 to veg in leo-20190211, found 6 pts.\n",
      "Fine-tuning label_k 6 to sand in leo-20190211, found 28 pts.\n",
      "Fine-tuning label_k 7 to no_sand in leo-20190211, found 41 pts.\n",
      "Fine-tuning label_k 0 to sand in leo-20190328, found 6 pts.\n",
      "Fine-tuning label_k 0 to no_sand in leo-20190328, found 52 pts.\n",
      "Fine-tuning label_k 1 to sand in leo-20190328, found 21 pts.\n",
      "Fine-tuning label_k 1 to no_sand in leo-20190328, found 2 pts.\n",
      "Fine-tuning label_k 2 to sand in leo-20190328, found 16 pts.\n",
      "Fine-tuning label_k 4 to sand in leo-20190328, found 25 pts.\n",
      "Fine-tuning label_k 5 to veg in leo-20190328, found 3 pts.\n",
      "Fine-tuning label_k 1 to sand in leo-20190731, found 5 pts.\n",
      "Fine-tuning label_k 3 to no_sand in leo-20190731, found 11 pts.\n",
      "Fine-tuning label_k 7 to no_sand in leo-20190731, found 72 pts.\n",
      "Fine-tuning label_k 6 to sand in leo-20190731, found 25 pts.\n",
      "Fine-tuning label_k 6 to veg in leo-20190731, found 42 pts.\n",
      "Fine tuning in mar.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f625d7f90e542d096993d87a12435fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning label_k 3 to water in mar-20180601, found 163 pts.\n",
      "Fine-tuning label_k 7 to no_sand in mar-20180601, found 15 pts.\n",
      "Fine-tuning label_k 7 to sand in mar-20180601, found 53 pts.\n",
      "Fine-tuning label_k 1 to sand in mar-20180621, found 48 pts.\n",
      "Fine-tuning label_k 3 to sand in mar-20180621, found 42 pts.\n",
      "Fine-tuning label_k 2 to water in mar-20180727, found 98 pts.\n",
      "Fine-tuning label_k 4 to sand in mar-20180727, found 29 pts.\n",
      "Fine-tuning label_k 2 to no_sand in mar-20181211, found 45 pts.\n",
      "Fine-tuning label_k 1 to water in mar-20181211, found 149 pts.\n",
      "Fine-tuning label_k 2 to water in mar-20190205, found 304 pts.\n",
      "Fine-tuning label_k 3 to no_sand in mar-20190205, found 23 pts.\n",
      "Fine-tuning label_k 2 to water in mar-20190313, found 100 pts.\n",
      "Fine-tuning label_k 5 to no_sand in mar-20190313, found 77 pts.\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "watermask  provided in CRS: epsg:32754\n",
      "Applying watermasks cleaning.\n",
      "Watermasking in mar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5f13280f914458b65fb052d493d3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 750 pts overlapping provided watermasks.\n",
      "Setting to water 532 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 710 pts overlapping provided watermasks.\n",
      "Setting to water 532 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 599 pts overlapping provided watermasks.\n",
      "Setting to water 557 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 339 pts overlapping provided watermasks.\n",
      "Setting to water 133 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 441 pts overlapping provided watermasks.\n",
      "Watermasking in leo.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1d7938e2654440a8a7d3c75d3498e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 652 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 555 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 638 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 627 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 583 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to water 643 pts overlapping provided watermasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:828: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoremask  provided in CRS: epsg:32754\n",
      "Applying shoremasks cleaning.\n",
      "Shoremasking in mar.\n",
      "Removing 3621 pts falling outside provided shore polygones.\n",
      "Shoremasking in leo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\base.py:39: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 2358 pts falling outside provided shore polygones.\n",
      "['polygon finetuning', 'watermasking', 'shoremasking'] completed.\n"
     ]
    }
   ],
   "source": [
    "P.cleanit(l_dicts=l_dicts,\n",
    "          watermasks_path=watermasks_path,\n",
    "          shoremasks_path=shoremasks_path,\n",
    "          label_corrections_path=label_corrections_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelled_dataset=P.profiles\n",
    "cluster_field='label_k'\n",
    "fill_class='sand'\n",
    "\n",
    "check_dicts_duplicated_values(l_dicts)\n",
    "\n",
    "labelled_dataset[\"pt_class\"]=np.nan\n",
    "print(type(labelled_dataset))\n",
    "\n",
    "all_keys = set().union(*(d.keys() for d in [i for i in l_dicts.values()]))\n",
    "class_names=l_dicts.keys()\n",
    "\n",
    "classed_df=pd.DataFrame()\n",
    "\n",
    "for loc in labelled_dataset.location.unique():\n",
    "    data_in_loc=labelled_dataset.query(f\"location=='{loc}'\")[[\"location\",\"raw_date\",cluster_field,\"pt_class\",'point_id']]\n",
    "\n",
    "    for raw_date in data_in_loc.raw_date.unique():\n",
    "        loc_date_tag=f\"{loc}_{raw_date}\"\n",
    "        data_in=data_in_loc.query(f\"raw_date=='{int(raw_date)}'\")\n",
    "\n",
    "        if loc_date_tag in all_keys:\n",
    "\n",
    "            for class_in in class_names:\n",
    "\n",
    "                if loc_date_tag in l_dicts[class_in].keys():\n",
    "                    loc_date_class_values=l_dicts[class_in][loc_date_tag]\n",
    "\n",
    "                    if len(loc_date_class_values)>=1:\n",
    "                        tmp_dict={label_k:class_in for label_k in loc_date_class_values}\n",
    "                        data_in['pt_class'].update(data_in[cluster_field].map(tmp_dict))\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            print(f\"{loc_date_tag} not in the class dictionaries. All their labels assigned to fill_class {fill_class}.\")\n",
    "            data_in[\"pt_class\"].fillna(fill_class, inplace=True)\n",
    "\n",
    "        classed_df=pd.concat([classed_df,data_in], ignore_index=True)\n",
    "\n",
    "merged=labelled_dataset.iloc[:,:-1].merge(right=classed_df[['point_id','pt_class']], on='point_id', how='left')\n",
    "\n",
    "merged[\"pt_class\"].fillna(fill_class, inplace=True)\n",
    "print(type(merged))\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dicts_duplicated_values(l_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_labelk(P.profiles, l_dicts).pt_class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProfileDynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"Undefined\", \"Small\", \"Medium\", \"High\", \"Extreme\"]\n",
    "appendix=[\"_deposition\", \"_erosion\"]\n",
    "\n",
    "\n",
    "D = ProfileDynamics(P, bins=5, method=\"JenksCaspall\", labels=labels)\n",
    "\n",
    "D.compute_multitemporal(loc_full={'mar': 'Marengo',\n",
    "         'leo': 'St. Leonards'})\n",
    "\n",
    "D.LISA_site_level(mode=\"distance\", distance_value=35)\n",
    "\n",
    "D.discretise(absolute=True, print_summary=True)\n",
    "\n",
    "D.infer_weights()\n",
    "\n",
    "D.BCD_compute_location(\"geometry\",\"all\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel_dict={\"Undefined_erosion\":\"ue\",\n",
    "\"Small_erosion\":\"se\",\n",
    "\"Medium_erosion\":\"me\",\n",
    "\"High_erosion\":\"he\",\n",
    "\"Extreme_erosion\":\"ee\",\n",
    " \"Undefined_deposition\":\"ud\",\n",
    " \"Small_deposition\":\"sd\",\n",
    " \"Medium_deposition\":\"md\",\n",
    " \"High_deposition\":\"hd\",\n",
    " \"Extreme_deposition\":\"ed\"\n",
    "}\n",
    "\n",
    "D.plot_trans_matrices(relabel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.BCD_compute_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.compute_volumetrics(lod=D.lod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_subset=[\"mar\"] # the function is optimised for single-location plots, but you can also pass a list of location codes\n",
    "colors_dict={\"mar\":'r',        # if you use multiple locations, then dictionary key is the location code and value the color\n",
    "            \"leo\":'b'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_transects(location='mar', tr_id=10, dt=['dt_0','dt_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_transect_mecs(location='leo',tr_id=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_single_loc([\"mar\"],None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"subset\" # if 'subset', only the provided location_subset and dt_subset will be plotted. If 'all', plot all.\n",
    "location_subset=['mar'] # provide a list of location codes. Only these locations will be plotted\n",
    "y_heat_bottom_limit=9 # bottom limit of the heatmaps (altimetric change)\n",
    "ax2_y_lims=[-1.5,1.5] # axis limit of the alongshore volumetric plot\n",
    "dt_subset=[\"dt_0\",\"dt_3\"]\n",
    "\n",
    "D.plot_alongshore_change(mode=mode, lod=0.05,dt_subset=dt_subset,\n",
    "                        location_subset=location_subset,\n",
    "                        y_heat_bottom_limit=y_heat_bottom_limit,\n",
    "                        ax2_y_lims=ax2_y_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_mec_evolution(location_field=\"location\",\n",
    "                     loc_order=[\"leo\",\"mar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out=r'C:\\my_packages\\sandpyper\\tests\\test_data'\n",
    "name=\"test\"\n",
    "D.save(name,dir_out)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=pickle.load(open(r\"C:\\my_packages\\sandpyper\\tests\\test_data\\test.p\", \"rb\"))\n",
    "\n",
    "loc_subset=[\"mar\"] # the function is optimised for single-location plots, but you can also pass a list of location codes\n",
    "colors_dict={\"mar\":'r',        # if you use multiple locations, then dictionary key is the location code and value the color\n",
    "            \"leo\":'b'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
