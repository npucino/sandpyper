{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><center> <b>Sandpyper: sandy beaches SfM-UAV analysis tools</b></center></font>\n",
    "<font size=\"4\"><center> <b> Example 2 - Sand labelling </b></center> <br>\n",
    "\n",
    "    \n",
    "<center><img src=\"images/banner.png\" width=\"80%\"  /></center>\n",
    "\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Sand clustering with Silhouette Analysis and KMeans notebook</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Nicolas Pucino; PhD Student @ Deakin University, Australia </b> <br>\n",
    "\n",
    "<font size=\"3\">This notebook illustrates how to use Sandpyper to perform Silhouette Analysis and KMeans on all previously extracted points. <br>\n",
    "\n",
    "<b>This notebook covers the following concepts:</b>\n",
    "\n",
    "- Silhouete Analysis.\n",
    "- KMeans clustering.\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from sandpyper.outils import coords_to_points \n",
    "from sandpyper.labels import get_sil_location, get_opt_k, kmeans_sa\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the project-related lists\n",
    "\n",
    "- loc codes\n",
    "- crs dict string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location codes used troughout the analysis\n",
    "loc_codes=[\"mar\",\"leo\"]\n",
    "\n",
    "# The Coordinate Reference Systems used troughout this study\n",
    "crs_dict_string= {\n",
    "                 'mar': {'init': 'epsg:32754'},\n",
    "                 'leo': {'init': 'epsg:32755'},\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, merging and preparing the tables\n",
    "\n",
    "The function __get_merged_table__ merge the rgb and z tables together and format it in a way it is digestible for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Loading the tables\n",
    "\n",
    "rgb_table_path=r\"C:\\my_packages\\sandpyper\\tests\\test_outputs\\gdf_rgb.csv\"\n",
    "z_table_path=r\"C:\\my_packages\\sandpyper\\tests\\test_outputs\\gdf.csv\"\n",
    "\n",
    "rgb_table=gpd.read_file(rgb_table_path)\n",
    "z_table=gpd.read_file(z_table_path)\n",
    "\n",
    "# As the distance (across-transect) comes from an interpolation, it has too many digits.\n",
    "# let's round both tables distance columns to 2 significant values and assign their data type as \"float\".\n",
    "\n",
    "rgb_table[\"distance\"]=np.round(rgb_table.loc[:,\"distance\"].values.astype(\"float\"),2)\n",
    "z_table[\"distance\"]=np.round(z_table.loc[:,\"distance\"].values.astype(\"float\"),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing Geodataframes as CSV is handy, but __we lose the column data type information__.\n",
    "Especially important is the __geometry column__, which we need to convert back into __Shapely Point object format__.\n",
    "To do that, the function __coords_to_points__ can be used across a Series ('geometry'). It can take quite a bit of time, so, if you have a lot of points, get ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731646.903760184 5705523.468988597)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61121091m2580400ar00</td>\n",
       "      <td>731646.903760184</td>\n",
       "      <td>5705523.468988597</td>\n",
       "      <td>POINT (731646.904 5705523.469)</td>\n",
       "      <td>114.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731646.0783010386 5705524.033450465)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61123091m2580600ar10</td>\n",
       "      <td>731646.0783010386</td>\n",
       "      <td>5705524.033450465</td>\n",
       "      <td>POINT (731646.078 5705524.033)</td>\n",
       "      <td>117.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731645.2528418931 5705524.597912331)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61129091m2530100ar20</td>\n",
       "      <td>731645.2528418931</td>\n",
       "      <td>5705524.597912331</td>\n",
       "      <td>POINT (731645.253 5705524.598)</td>\n",
       "      <td>122.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731644.4273827478 5705525.162374198)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61124091m2570800ar30</td>\n",
       "      <td>731644.4273827478</td>\n",
       "      <td>5705525.162374198</td>\n",
       "      <td>POINT (731644.427 5705525.162)</td>\n",
       "      <td>125.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>21</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731643.6019236024 5705525.726836066)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>61120091m2520400ar40</td>\n",
       "      <td>731643.6019236024</td>\n",
       "      <td>5705525.726836066</td>\n",
       "      <td>POINT (731643.602 5705525.727)</td>\n",
       "      <td>126.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance         z tr_id  raw_date  \\\n",
       "0       0.0  0.007440    21  20190516   \n",
       "1       1.0  0.008439    21  20190516   \n",
       "2       2.0  0.010800    21  20190516   \n",
       "3       3.0  0.011350    21  20190516   \n",
       "4       4.0  0.028030    21  20190516   \n",
       "\n",
       "                                   coordinates location survey_date  \\\n",
       "0   POINT (731646.903760184 5705523.468988597)      mar  2019-05-16   \n",
       "1  POINT (731646.0783010386 5705524.033450465)      mar  2019-05-16   \n",
       "2  POINT (731645.2528418931 5705524.597912331)      mar  2019-05-16   \n",
       "3  POINT (731644.4273827478 5705525.162374198)      mar  2019-05-16   \n",
       "4  POINT (731643.6019236024 5705525.726836066)      mar  2019-05-16   \n",
       "\n",
       "               point_id                  x                  y  \\\n",
       "0  61121091m2580400ar00   731646.903760184  5705523.468988597   \n",
       "1  61123091m2580600ar10  731646.0783010386  5705524.033450465   \n",
       "2  61129091m2530100ar20  731645.2528418931  5705524.597912331   \n",
       "3  61124091m2570800ar30  731644.4273827478  5705525.162374198   \n",
       "4  61120091m2520400ar40  731643.6019236024  5705525.726836066   \n",
       "\n",
       "                         geometry  band1  band2  band3  \n",
       "0  POINT (731646.904 5705523.469)  114.0  139.0  128.0  \n",
       "1  POINT (731646.078 5705524.033)  117.0  139.0  127.0  \n",
       "2  POINT (731645.253 5705524.598)  122.0  140.0  127.0  \n",
       "3  POINT (731644.427 5705525.162)  125.0  144.0  133.0  \n",
       "4  POINT (731643.602 5705525.727)  126.0  145.0  133.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we merge the two tables (storing elevation and rgb information)\n",
    "\n",
    "data_merged = pd.merge(z_table,rgb_table[[\"band1\",\"band2\",\"band3\",\"point_id\"]],on=\"point_id\",validate=\"one_to_one\")\n",
    "\n",
    "# replace empty values with np.NaN\n",
    "data_merged=data_merged.replace(\"\", np.NaN)\n",
    "\n",
    "# and convert the z column into floats.\n",
    "data_merged['z']=data_merged.z.astype(\"float\")\n",
    "\n",
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we add two features, slope and curvature, computed from the elevation series,\n",
    "# in case we wnat to use for KMeans clustering.\n",
    "# Note that when passing from one transect to another, slope and curvature computations are wrong.\n",
    "# However, we will clip those areas as they are in the water or in the backdune.\n",
    "\n",
    "data_merged[\"slope\"]=np.gradient(data_merged.z)\n",
    "data_merged[\"curve\"]=np.gradient(data_merged.slope)\n",
    "\n",
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our rasters have NaN values set to -32767.0. Thus, we replace them with np.Nan.\n",
    "data_merged.z.replace(-32767.0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The __get_sil_location__ function will iteratively perform KMeans clustering and Silhouette Analysis with increasing number of clusters (k, specified in the `ks` parameter) for every survey, using the feature set specified in the parameter `feature_set`.\n",
    "\n",
    "This will return a dataframe with Average Silhouette scores with different k for all surveys, which we use to find sub-optimal number of clusters with __get_opt_k__ function.\n",
    "\n",
    "Then, with the sub-optimal k, we finally run KMeans with __kmeans_sa__ function on all the surveys to obtain clustered points to visually discriminate between sand and non-sand in a Qgis environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df152761cf8412f980c41707b5e970d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f970dc274d354167bec4b75174c4d199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on : mar, 20190516.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9f4ae92d3431998407fd74103c47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.6219865168763407\n",
      "For n_clusters = 3 The average silhouette_score is : 0.535782834177223\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5360693626824162\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4560535847617118\n",
      "For n_clusters = 6 The average silhouette_score is : 0.45529082978244856\n",
      "For n_clusters = 7 The average silhouette_score is : 0.44623104595368007\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4276467073078296\n",
      "For n_clusters = 9 The average silhouette_score is : 0.39984472497160034\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3944833658664287\n",
      "For n_clusters = 11 The average silhouette_score is : 0.39290037915600995\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3626866522843635\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3537214969510808\n",
      "For n_clusters = 14 The average silhouette_score is : 0.360049558138258\n",
      "Working on : mar, 20190313.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235c79cd839140698d020cafae40fa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.557958595647791\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5140648301846097\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5018436513556769\n",
      "For n_clusters = 5 The average silhouette_score is : 0.433979206893076\n",
      "For n_clusters = 6 The average silhouette_score is : 0.417124057365699\n",
      "For n_clusters = 7 The average silhouette_score is : 0.41877526043796687\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3813644990945346\n",
      "For n_clusters = 9 The average silhouette_score is : 0.38298598316290156\n",
      "For n_clusters = 10 The average silhouette_score is : 0.38780357139523025\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3705944933198418\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3651637741592011\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3626901435079943\n",
      "For n_clusters = 14 The average silhouette_score is : 0.364312347054231\n",
      "Working on : mar, 20190205.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e180559c226d4a288ac755e3a9dd7d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5864811907668233\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5287826504696901\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5135421029464969\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4307716357147362\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4198951039452866\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4216561839748987\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4048963177852256\n",
      "For n_clusters = 9 The average silhouette_score is : 0.40309220394346107\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3863324302013023\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3797930282754271\n",
      "For n_clusters = 12 The average silhouette_score is : 0.38096229910474133\n",
      "For n_clusters = 13 The average silhouette_score is : 0.38270148296414735\n",
      "For n_clusters = 14 The average silhouette_score is : 0.38101196831610196\n",
      "Working on : mar, 20181211.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f58d9dce3014f269048515ee050b01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5408421089322027\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5230591336669079\n",
      "For n_clusters = 4 The average silhouette_score is : 0.5212604455141028\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4229400387683722\n",
      "For n_clusters = 6 The average silhouette_score is : 0.45245862927127983\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4483238394769186\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4196417680949735\n",
      "For n_clusters = 9 The average silhouette_score is : 0.40611511715414134\n",
      "For n_clusters = 10 The average silhouette_score is : 0.38659542553842996\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3696055524901218\n",
      "For n_clusters = 12 The average silhouette_score is : 0.37009962399500085\n",
      "For n_clusters = 13 The average silhouette_score is : 0.35527656663572244\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3465435289160837\n",
      "Working on : mar, 20181113.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a048c3e19c74737942a5d91d0e6f7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5653353599190023\n",
      "For n_clusters = 3 The average silhouette_score is : 0.48082172651613736\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4739355249881875\n",
      "For n_clusters = 5 The average silhouette_score is : 0.44998542160594424\n",
      "For n_clusters = 6 The average silhouette_score is : 0.46793686792032685\n",
      "For n_clusters = 7 The average silhouette_score is : 0.45141377362406754\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4282875609756635\n",
      "For n_clusters = 9 The average silhouette_score is : 0.41407851845524357\n",
      "For n_clusters = 10 The average silhouette_score is : 0.40718423656045105\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3903647922431344\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3839833647433829\n",
      "For n_clusters = 13 The average silhouette_score is : 0.38065272471925277\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3832072967705472\n",
      "Working on : mar, 20180925.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e56dd8fb30149d6b1553363cdf3aae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5781993163219185\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5170856406873439\n",
      "For n_clusters = 4 The average silhouette_score is : 0.48466929384434043\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4373504056027659\n",
      "For n_clusters = 6 The average silhouette_score is : 0.39375906953445383\n",
      "For n_clusters = 7 The average silhouette_score is : 0.38864190848914665\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4035256487664215\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3798356038299367\n",
      "For n_clusters = 10 The average silhouette_score is : 0.37962054426443537\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3644375001522226\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3558265298038209\n",
      "For n_clusters = 13 The average silhouette_score is : 0.34528697717595713\n",
      "For n_clusters = 14 The average silhouette_score is : 0.35004508855406896\n",
      "Working on : mar, 20180727.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef485eb843a54499a2de0cfa9e7c18a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5803251747670938\n",
      "For n_clusters = 3 The average silhouette_score is : 0.48850610227959923\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4772654299979584\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4135001777584117\n",
      "For n_clusters = 6 The average silhouette_score is : 0.38283314263428714\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3755827513627956\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3486272625814806\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3367906257895182\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3273888373123684\n",
      "For n_clusters = 11 The average silhouette_score is : 0.30071888963336296\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3219840164575009\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3222155159146202\n",
      "For n_clusters = 14 The average silhouette_score is : 0.307958370621084\n",
      "Working on : mar, 20180621.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7457b46e4d6f4f31af82f2c2f9a3bf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.5439589764752933\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4387708619085413\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4501935908699898\n",
      "For n_clusters = 5 The average silhouette_score is : 0.3963414382040067\n",
      "For n_clusters = 6 The average silhouette_score is : 0.41807731086369254\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3871968978951222\n",
      "For n_clusters = 8 The average silhouette_score is : 0.37393061831106983\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3443142601476958\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3585650473719073\n",
      "For n_clusters = 11 The average silhouette_score is : 0.35570748604269775\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3575633171508779\n",
      "For n_clusters = 13 The average silhouette_score is : 0.37087632012718563\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3795271430686032\n",
      "Working on : mar, 20180601.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658342cf47404f15a555255c0edbe2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.48270415311106846\n",
      "For n_clusters = 3 The average silhouette_score is : 0.3772084152830261\n",
      "For n_clusters = 4 The average silhouette_score is : 0.38234628609235827\n",
      "For n_clusters = 5 The average silhouette_score is : 0.38128225187445997\n",
      "For n_clusters = 6 The average silhouette_score is : 0.36428432858349613\n",
      "For n_clusters = 7 The average silhouette_score is : 0.36240034713437685\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3701424025696913\n",
      "For n_clusters = 9 The average silhouette_score is : 0.37175207788683484\n",
      "For n_clusters = 10 The average silhouette_score is : 0.37676977350569846\n",
      "For n_clusters = 11 The average silhouette_score is : 0.37582649170780724\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3619596723553155\n",
      "For n_clusters = 13 The average silhouette_score is : 0.360705274650356\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3549151019500089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4619e773254375b52283751d7a3c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on : leo, 20190731.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ee3049afd84d7ea0a79a9e54d08646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.3899198233106219\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5071438060156596\n",
      "For n_clusters = 4 The average silhouette_score is : 0.47005119135652856\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4481907289981238\n",
      "For n_clusters = 6 The average silhouette_score is : 0.42502882450684076\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4011433092740131\n",
      "For n_clusters = 8 The average silhouette_score is : 0.38998808479733066\n",
      "For n_clusters = 9 The average silhouette_score is : 0.38559916622535073\n",
      "For n_clusters = 10 The average silhouette_score is : 0.38736594985557654\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3788805356672864\n",
      "For n_clusters = 12 The average silhouette_score is : 0.37132878563783606\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3728000521740459\n",
      "For n_clusters = 14 The average silhouette_score is : 0.37291633707910765\n",
      "Working on : leo, 20190328.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d751c91127e042779e9a594157e064c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.3988524141238273\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4304685615621422\n",
      "For n_clusters = 4 The average silhouette_score is : 0.431227035737659\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4509750902886234\n",
      "For n_clusters = 6 The average silhouette_score is : 0.42012497505273527\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4094032569946379\n",
      "For n_clusters = 8 The average silhouette_score is : 0.42729379253757904\n",
      "For n_clusters = 9 The average silhouette_score is : 0.41690585873078206\n",
      "For n_clusters = 10 The average silhouette_score is : 0.4226788217215935\n",
      "For n_clusters = 11 The average silhouette_score is : 0.41351261817558693\n",
      "For n_clusters = 12 The average silhouette_score is : 0.4087415403998031\n",
      "For n_clusters = 13 The average silhouette_score is : 0.38543846003780563\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3783301865582882\n",
      "Working on : leo, 20190211.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea9435393d5455884e70e6437c7fdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.3811803323084047\n",
      "For n_clusters = 3 The average silhouette_score is : 0.48727929000883047\n",
      "For n_clusters = 4 The average silhouette_score is : 0.44313687819005354\n",
      "For n_clusters = 5 The average silhouette_score is : 0.45097582364485633\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4320727369612193\n",
      "For n_clusters = 7 The average silhouette_score is : 0.4166514336483687\n",
      "For n_clusters = 8 The average silhouette_score is : 0.39445247084076124\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3718047003108205\n",
      "For n_clusters = 10 The average silhouette_score is : 0.36905766574894283\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3723670925736636\n",
      "For n_clusters = 12 The average silhouette_score is : 0.35518841237259613\n",
      "For n_clusters = 13 The average silhouette_score is : 0.35415290301652735\n",
      "For n_clusters = 14 The average silhouette_score is : 0.33383141602938693\n",
      "Working on : leo, 20180920.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69cbb15b3aa4de18337c38ec92f4ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.4039166622963731\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4367493135688848\n",
      "For n_clusters = 4 The average silhouette_score is : 0.42434419318841404\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4443994359362926\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4175864662989779\n",
      "For n_clusters = 7 The average silhouette_score is : 0.38860870508958795\n",
      "For n_clusters = 8 The average silhouette_score is : 0.38880003508342514\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3830287983992327\n",
      "For n_clusters = 10 The average silhouette_score is : 0.37353163965128733\n",
      "For n_clusters = 11 The average silhouette_score is : 0.36620965721819637\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3536600836899299\n",
      "For n_clusters = 13 The average silhouette_score is : 0.3585083805642395\n",
      "For n_clusters = 14 The average silhouette_score is : 0.35672016047028215\n",
      "Working on : leo, 20180713.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f7f9f6a62848b7a1ac664ce7c8415a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.49629965872244686\n",
      "For n_clusters = 3 The average silhouette_score is : 0.5092406492417487\n",
      "For n_clusters = 4 The average silhouette_score is : 0.46159478658042724\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4488595142176017\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4183623304561938\n",
      "For n_clusters = 7 The average silhouette_score is : 0.39004221840210485\n",
      "For n_clusters = 8 The average silhouette_score is : 0.3842278112748862\n",
      "For n_clusters = 9 The average silhouette_score is : 0.36304035595403583\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3463760386521644\n",
      "For n_clusters = 11 The average silhouette_score is : 0.34841430296451464\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3460546307634773\n",
      "For n_clusters = 13 The average silhouette_score is : 0.34457917043266856\n",
      "For n_clusters = 14 The average silhouette_score is : 0.3318667826222712\n",
      "Working on : leo, 20180606.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0376aad37ddf4887bd7bdad288e93d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.4012079287817844\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4563078554750914\n",
      "For n_clusters = 4 The average silhouette_score is : 0.40640166442880776\n",
      "For n_clusters = 5 The average silhouette_score is : 0.4001757072050638\n",
      "For n_clusters = 6 The average silhouette_score is : 0.3890044660503746\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3716889344520391\n",
      "For n_clusters = 8 The average silhouette_score is : 0.36600629265911533\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3503569988098764\n",
      "For n_clusters = 10 The average silhouette_score is : 0.34651080656561367\n",
      "For n_clusters = 11 The average silhouette_score is : 0.34322073624826754\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3439561998875081\n",
      "For n_clusters = 13 The average silhouette_score is : 0.347961415981389\n",
      "For n_clusters = 14 The average silhouette_score is : 0.33782737875946023\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run interatively KMeans + SA\n",
    "\n",
    "feature_set=[\"band1\",\"band2\",\"band3\",\"distance\"]\n",
    "sil_df=get_sil_location(data_merged,\n",
    "                        ks=(2,15), \n",
    "                        feature_set=feature_set,\n",
    "                       random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>k</th>\n",
       "      <th>silhouette_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.621987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>3</td>\n",
       "      <td>0.535783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>4</td>\n",
       "      <td>0.536069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>5</td>\n",
       "      <td>0.456054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>20190516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.455291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location  raw_date  k  silhouette_mean\n",
       "0      mar  20190516  2         0.621987\n",
       "1      mar  20190516  3         0.535783\n",
       "2      mar  20190516  4         0.536069\n",
       "3      mar  20190516  5         0.456054\n",
       "4      mar  20190516  6         0.455291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sil_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sub-optimal k\n",
    "\n",
    "Find sub-optimal k by searching inflexion points where an additional cluster do not considerably degrade the overall clustering performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leo_20180606': 11,\n",
       " 'leo_20180713': 10,\n",
       " 'leo_20180920': 4,\n",
       " 'leo_20190211': 4,\n",
       " 'leo_20190328': 7,\n",
       " 'leo_20190731': 9,\n",
       " 'mar_20180601': 3,\n",
       " 'mar_20180621': 3,\n",
       " 'mar_20180727': 11,\n",
       " 'mar_20180925': 7,\n",
       " 'mar_20181113': 5,\n",
       " 'mar_20181211': 5,\n",
       " 'mar_20190205': 6,\n",
       " 'mar_20190313': 6,\n",
       " 'mar_20190516': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_k=get_opt_k(sil_df, sigma=0 )\n",
    "opt_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not satisfied with the sub-optimal k returned by the algorithm, we can manually specify each survey k\n",
    "by defining a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on our observations on a dataset comprising 87 surveys, 10 clusters (k=10) is generally a good tradeoff.\n",
    "\n",
    "opt_k={'leo_2018-06-06': 10,\n",
    " 'leo_2018-07-13': 10,\n",
    " 'leo_2018-09-20': 10,\n",
    " 'leo_2019-02-11': 10,\n",
    " 'leo_2019-03-28': 10,\n",
    " 'leo_2019-07-31': 10,\n",
    " 'mar_2018-06-01': 10,\n",
    " 'mar_2018-06-21': 10,\n",
    " 'mar_2018-07-27': 10,\n",
    " 'mar_2018-09-25': 10,\n",
    " 'mar_2018-11-13': 10,\n",
    " 'mar_2018-12-11': 10,\n",
    " 'mar_2019-02-05': 10,\n",
    " 'mar_2019-03-13': 10,\n",
    " 'mar_2019-05-16': 10}\n",
    "\n",
    "opt_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, update one value only. For instance, in mar_2019-05-16 dataset, it is unlikely that 3 clusters are enough.<br>\n",
    "So, we replace only that value with 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_k['mar_2019-05-16']=10\n",
    "opt_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised K-Means clustering\n",
    "\n",
    "With the sub-optimal k dictionary and keeping the same feature set, we finally cluster the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distance', 'z', 'tr_id', 'raw_date', 'coordinates', 'location',\n",
       "       'survey_date', 'point_id', 'x', 'y', 'geometry', 'band1', 'band2',\n",
       "       'band3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distance', 'z', 'tr_id', 'raw_date', 'coordinates', 'location',\n",
       "       'survey_date', 'point_id', 'x', 'y', 'geometry', 'band1', 'band2',\n",
       "       'band3', 'label_k'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classified.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740aa539b41f480fb326cef439a237fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e3ee08a9e74ff2981a4b83879a7cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a263220a9794c9895b0b37884ff1f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_set=[\"band1\",\"band2\",\"band3\",\"distance\"]\n",
    "data_classified=kmeans_sa(data_merged,opt_k, feature_set=feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classified2 = pd.merge(data_classified[[\"point_id\",\"label_k\"]], data_merged, how=\"left\", on=\"point_id\", validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sandpyper.dynamics import compute_multitemporal\n",
    "from sandpyper.outils import create_details_df, create_spatial_id\n",
    "loc_full={'mar': 'Marengo',\n",
    "         'leo': 'St. Leonards'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multitemporal (df,\n",
    "                           filter_sand=True,\n",
    "                           date_field='survey_date',\n",
    "                          sand_label_field='label_sand',\n",
    "                           filter_classes=[0]):\n",
    "    \"\"\"\n",
    "    From a dataframe containing the extracted points and a column specifying wether they are sand or non-sand, returns a multitemporal dataframe\n",
    "    with time-periods sand-specific elevation changes.\n",
    "\n",
    "    Args:\n",
    "        date_field (str): the name of the column storing the survey date.\n",
    "        sand_label_field (str): the name of the column storing the sand label (usually sand=0, no_sand=1).\n",
    "        filter_classes (list): list of integers specifiying the label numbers of the sand_label_field that are sand. Default [0].\n",
    "        common_field (str): name of the field where the points share the same name. It is usually the geometry or spatial IDs.\n",
    "\n",
    "    Returns:\n",
    "        A multitemporal dataframe of sand-specific elevation changes.\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"spatial_id\"]=[create_spatial_id(df.iloc[i]) for i in range(df.shape[0])]\n",
    "    fusion_long=pd.DataFrame()\n",
    "\n",
    "    for location in df.location.unique():\n",
    "        print(f\"working on {location}\")\n",
    "        loc_data=df.query(f\"location=='{location}'\")\n",
    "        list_dates=loc_data.loc[:,date_field].unique()\n",
    "        list_dates.sort()\n",
    "\n",
    "\n",
    "        for i in range(list_dates.shape[0]):\n",
    "\n",
    "            if i < list_dates.shape[0]-1:\n",
    "                date_pre=list_dates[i]\n",
    "                date_post=list_dates[i+1]\n",
    "                print(f\"Calculating dt{i}, from {date_pre} to {date_post} in {location}.\")\n",
    "\n",
    "                if filter_sand:\n",
    "                    df_pre=loc_data.query(f\"{date_field} =='{date_pre}' & {sand_label_field} in {filter_classes}\").dropna(subset=['z'])\n",
    "                    df_post=loc_data.query(f\"{date_field} =='{date_post}' & {sand_label_field} in {filter_classes}\").dropna(subset=['z'])\n",
    "                else:\n",
    "                    df_pre=loc_data.query(f\"{date_field} =='{date_pre}'\").dropna(subset=['z'])\n",
    "                    df_post=loc_data.query(f\"{date_field} =='{date_post}'\").dropna(subset=['z'])\n",
    "\n",
    "                merged=pd.merge(df_pre,df_post, how='inner', on='spatial_id', validate=\"one_to_one\",suffixes=('_pre','_post'))\n",
    "                merged[\"dh\"]=merged.z_post.astype(float) - merged.z_pre.astype(float)\n",
    "\n",
    "                dict_short={\"geometry\": merged.geometry_pre,\n",
    "                            \"location\":location,\n",
    "                            \"tr_id\":merged.tr_id_pre,\n",
    "                            \"distance\":merged.distance_pre,\n",
    "                            \"dt\":  f\"dt_{i}\",\n",
    "                            \"date_pre\":date_pre,\n",
    "                            \"date_post\":date_post,\n",
    "                            \"z_pre\":merged.z_pre.astype(float),\n",
    "                            \"z_post\":merged.z_post.astype(float),\n",
    "                            \"dh\":merged.dh}\n",
    "\n",
    "                short_df=pd.DataFrame(dict_short)\n",
    "                fusion_long=pd.concat([short_df,fusion_long],ignore_index=True)\n",
    "\n",
    "    print(\"done\")\n",
    "    return fusion_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on leo\n",
      "Calculating dt0, from 20180606 to 20180713 in leo.\n",
      "Calculating dt1, from 20180713 to 20180920 in leo.\n",
      "Calculating dt2, from 20180920 to 20190211 in leo.\n",
      "Calculating dt3, from 20190211 to 20190328 in leo.\n",
      "Calculating dt4, from 20190328 to 20190731 in leo.\n",
      "working on mar\n",
      "Calculating dt0, from 20180601 to 20180621 in mar.\n",
      "Calculating dt1, from 20180621 to 20180727 in mar.\n",
      "Calculating dt2, from 20180727 to 20180925 in mar.\n",
      "Calculating dt3, from 20180925 to 20181113 in mar.\n",
      "Calculating dt4, from 20181113 to 20181211 in mar.\n",
      "Calculating dt5, from 20181211 to 20190205 in mar.\n",
      "Calculating dt6, from 20190205 to 20190313 in mar.\n",
      "Calculating dt7, from 20190313 to 20190516 in mar.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dh_df=compute_multitemporal(data_classified2,\n",
    "                     date_field='raw_date', filter_sand=False,\n",
    "                     sand_label_field='label_sand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>location</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>dt</th>\n",
       "      <th>date_pre</th>\n",
       "      <th>date_post</th>\n",
       "      <th>z_pre</th>\n",
       "      <th>z_post</th>\n",
       "      <th>dh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (731646.904 5705523.469)</td>\n",
       "      <td>mar</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dt_7</td>\n",
       "      <td>20190313</td>\n",
       "      <td>20190516</td>\n",
       "      <td>1.111801</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>-1.104360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (731646.078 5705524.033)</td>\n",
       "      <td>mar</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dt_7</td>\n",
       "      <td>20190313</td>\n",
       "      <td>20190516</td>\n",
       "      <td>1.124138</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-1.115699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (731645.253 5705524.598)</td>\n",
       "      <td>mar</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>dt_7</td>\n",
       "      <td>20190313</td>\n",
       "      <td>20190516</td>\n",
       "      <td>1.117822</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>-1.107022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (731644.427 5705525.162)</td>\n",
       "      <td>mar</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dt_7</td>\n",
       "      <td>20190313</td>\n",
       "      <td>20190516</td>\n",
       "      <td>1.148563</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>-1.137213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (731643.602 5705525.727)</td>\n",
       "      <td>mar</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>dt_7</td>\n",
       "      <td>20190313</td>\n",
       "      <td>20190516</td>\n",
       "      <td>1.112438</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>-1.084408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19862</th>\n",
       "      <td>POINT (300071.060 5773184.013)</td>\n",
       "      <td>leo</td>\n",
       "      <td>18</td>\n",
       "      <td>48.0</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>20180713</td>\n",
       "      <td>-0.435838</td>\n",
       "      <td>-0.624926</td>\n",
       "      <td>-0.189088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19863</th>\n",
       "      <td>POINT (300072.023 5773184.284)</td>\n",
       "      <td>leo</td>\n",
       "      <td>18</td>\n",
       "      <td>49.0</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>20180713</td>\n",
       "      <td>-0.431080</td>\n",
       "      <td>-0.642019</td>\n",
       "      <td>-0.210939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>POINT (300075.506 5773164.488)</td>\n",
       "      <td>leo</td>\n",
       "      <td>17</td>\n",
       "      <td>47.0</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>20180713</td>\n",
       "      <td>-0.316839</td>\n",
       "      <td>-0.478775</td>\n",
       "      <td>-0.161936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>POINT (300076.469 5773164.759)</td>\n",
       "      <td>leo</td>\n",
       "      <td>17</td>\n",
       "      <td>48.0</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>20180713</td>\n",
       "      <td>-0.459795</td>\n",
       "      <td>-0.477090</td>\n",
       "      <td>-0.017296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>POINT (300077.432 5773165.029)</td>\n",
       "      <td>leo</td>\n",
       "      <td>17</td>\n",
       "      <td>49.0</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>20180713</td>\n",
       "      <td>-0.557283</td>\n",
       "      <td>-0.493576</td>\n",
       "      <td>0.063707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19867 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geometry location tr_id  distance    dt  \\\n",
       "0      POINT (731646.904 5705523.469)      mar    21       0.0  dt_7   \n",
       "1      POINT (731646.078 5705524.033)      mar    21       1.0  dt_7   \n",
       "2      POINT (731645.253 5705524.598)      mar    21       2.0  dt_7   \n",
       "3      POINT (731644.427 5705525.162)      mar    21       3.0  dt_7   \n",
       "4      POINT (731643.602 5705525.727)      mar    21       4.0  dt_7   \n",
       "...                               ...      ...   ...       ...   ...   \n",
       "19862  POINT (300071.060 5773184.013)      leo    18      48.0  dt_0   \n",
       "19863  POINT (300072.023 5773184.284)      leo    18      49.0  dt_0   \n",
       "19864  POINT (300075.506 5773164.488)      leo    17      47.0  dt_0   \n",
       "19865  POINT (300076.469 5773164.759)      leo    17      48.0  dt_0   \n",
       "19866  POINT (300077.432 5773165.029)      leo    17      49.0  dt_0   \n",
       "\n",
       "       date_pre date_post     z_pre    z_post        dh  \n",
       "0      20190313  20190516  1.111801  0.007440 -1.104360  \n",
       "1      20190313  20190516  1.124138  0.008439 -1.115699  \n",
       "2      20190313  20190516  1.117822  0.010800 -1.107022  \n",
       "3      20190313  20190516  1.148563  0.011350 -1.137213  \n",
       "4      20190313  20190516  1.112438  0.028030 -1.084408  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "19862  20180606  20180713 -0.435838 -0.624926 -0.189088  \n",
       "19863  20180606  20180713 -0.431080 -0.642019 -0.210939  \n",
       "19864  20180606  20180713 -0.316839 -0.478775 -0.161936  \n",
       "19865  20180606  20180713 -0.459795 -0.477090 -0.017296  \n",
       "19866  20180606  20180713 -0.557283 -0.493576  0.063707  \n",
       "\n",
       "[19867 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_df.to_csv(r\"C:\\my_packages\\sandpyper\\tests\\test_outputs\\dh_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "details=create_details_df(dh_df, loc_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>date_pre</th>\n",
       "      <th>date_post</th>\n",
       "      <th>location</th>\n",
       "      <th>n_days</th>\n",
       "      <th>loc_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>20180713</td>\n",
       "      <td>leo</td>\n",
       "      <td>37</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_1</td>\n",
       "      <td>20180713</td>\n",
       "      <td>20180920</td>\n",
       "      <td>leo</td>\n",
       "      <td>69</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_2</td>\n",
       "      <td>20180920</td>\n",
       "      <td>20190211</td>\n",
       "      <td>leo</td>\n",
       "      <td>144</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt_3</td>\n",
       "      <td>20190211</td>\n",
       "      <td>20190328</td>\n",
       "      <td>leo</td>\n",
       "      <td>45</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt_4</td>\n",
       "      <td>20190328</td>\n",
       "      <td>20190731</td>\n",
       "      <td>leo</td>\n",
       "      <td>125</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt_0</td>\n",
       "      <td>20180601</td>\n",
       "      <td>20180621</td>\n",
       "      <td>mar</td>\n",
       "      <td>20</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dt_1</td>\n",
       "      <td>20180621</td>\n",
       "      <td>20180727</td>\n",
       "      <td>mar</td>\n",
       "      <td>36</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dt_2</td>\n",
       "      <td>20180727</td>\n",
       "      <td>20180925</td>\n",
       "      <td>mar</td>\n",
       "      <td>60</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dt_3</td>\n",
       "      <td>20180925</td>\n",
       "      <td>20181113</td>\n",
       "      <td>mar</td>\n",
       "      <td>49</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dt_4</td>\n",
       "      <td>20181113</td>\n",
       "      <td>20181211</td>\n",
       "      <td>mar</td>\n",
       "      <td>28</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dt_5</td>\n",
       "      <td>20181211</td>\n",
       "      <td>20190205</td>\n",
       "      <td>mar</td>\n",
       "      <td>56</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dt_6</td>\n",
       "      <td>20190205</td>\n",
       "      <td>20190313</td>\n",
       "      <td>mar</td>\n",
       "      <td>36</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dt_7</td>\n",
       "      <td>20190313</td>\n",
       "      <td>20190516</td>\n",
       "      <td>mar</td>\n",
       "      <td>64</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dt  date_pre date_post location  n_days      loc_full\n",
       "0   dt_0  20180606  20180713      leo      37  St. Leonards\n",
       "1   dt_1  20180713  20180920      leo      69  St. Leonards\n",
       "2   dt_2  20180920  20190211      leo     144  St. Leonards\n",
       "3   dt_3  20190211  20190328      leo      45  St. Leonards\n",
       "4   dt_4  20190328  20190731      leo     125  St. Leonards\n",
       "5   dt_0  20180601  20180621      mar      20       Marengo\n",
       "6   dt_1  20180621  20180727      mar      36       Marengo\n",
       "7   dt_2  20180727  20180925      mar      60       Marengo\n",
       "8   dt_3  20180925  20181113      mar      49       Marengo\n",
       "9   dt_4  20181113  20181211      mar      28       Marengo\n",
       "10  dt_5  20181211  20190205      mar      56       Marengo\n",
       "11  dt_6  20190205  20190313      mar      36       Marengo\n",
       "12  dt_7  20190313  20190516      mar      64       Marengo"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.to_csv(r\"C:\\my_packages\\sandpyper\\tests\\test_outputs\\dt_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOOD!\n",
    "\n",
    "save the __data_classified__ dataframe as a CSV file and head to the __Example_3_Labels_correction_and_multitemporal_table notebook__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classified.to_csv(r\"C:\\my_packages\\sandpyper\\tests\\test_outputs\\data_classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
